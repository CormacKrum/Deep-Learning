{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec Model\n",
    "* Word2Vec Google's Pretrained Model\n",
    "* Contains vector representations of 50 billion words\n",
    "* Words which are similar in context have similar vectors\n",
    "* Distance/Similarity between two words can be measured using Cosine Distance\n",
    "\n",
    "# Applications\n",
    "* Text Similarity\n",
    "* Language Translation\n",
    "* Finding Odd Words\n",
    "* Word Analogies\n",
    "\n",
    "# Word Embeddings\n",
    "* Word embeddings are numerical representation of words, in the form of vectors.\n",
    "* Word2Vec Model represents each word as 300 Dimensional Vector\n",
    "* In this tutorial we are going to see how to use pre-trained word2vec model.\n",
    "* Model size is around 1.5 GB\n",
    "* We will work using Gensim, which is popular NLP Package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Gensim's Word2Vec Model provides optimum implementation of\n",
    "\n",
    "1) CBOW Model : Efficient Estimation of Word Representations in Vector Space\n",
    "\n",
    "2) SkipGram Model : The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that \n",
    "capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the \n",
    "vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. \n",
    "We also describe a simple alternative to the hierarchical softmax called negative sampling. An inherent limitation of word representations is their indifference\n",
    "to word order and their inability to represent idiomatic phrases. For example, the meanings of \"Canada\" and \"Air\" cannot be easily combined to obtain \n",
    "\"Air Canada\". Motivated by this example, we present a simple method for finding phrases in text, and show that learning good vector representations \n",
    "for millions of phrases is possible.\n",
    "\n",
    "\n",
    " Word2Vec using Gensim\n",
    " \n",
    " Link https://radimrehurek.com/gensim/models/word2vec.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import word2vec,KeyedVectors\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vector = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin',binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_apple = word_vector[\"apple\"]\n",
    "v_mango = word_vector[\"mango\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "print(v_apple.shape)\n",
    "print(v_mango.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.57518554]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity([v_apple],[v_mango])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def odd_one_out(words):\n",
    "    vec_word=[]\n",
    "    for i in words:\n",
    "        vec_word.append(word_vector[i])\n",
    "    vec_word = np.array(vec_word)\n",
    "    word_vec_avg = np.sum(vec_word,axis=0)\n",
    "    similarity_list = []\n",
    "    for i in range(len(words)):\n",
    "        similarity = cosine_similarity([vec_word[i]],[word_vec_avg])[0][0]\n",
    "        similarity_list.append(similarity)\n",
    "    x = np.argmin(np.array(similarity_list))\n",
    "    return words[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1 = [\"apple\",\"mango\",\"juice\",\"party\",\"orange\"] \n",
    "input_2 = [\"music\",\"dance\",\"sleep\",\"dancer\",\"food\"]        \n",
    "input_3  = [\"match\",\"player\",\"football\",\"cricket\",\"dancer\"]\n",
    "input_4 = [\"india\",\"paris\",\"russia\",\"france\",\"germany\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "party\n",
      "sleep\n",
      "dancer\n",
      "paris\n"
     ]
    }
   ],
   "source": [
    "print(odd_one_out(input_1))\n",
    "print(odd_one_out(input_2))\n",
    "print(odd_one_out(input_3))\n",
    "print(odd_one_out(input_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(\"Dataset/Test.csv\")\n",
    "X_test.head()\n",
    "X_test = X_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for i in range(X_test.shape[0]):\n",
    "    y_out = odd_one_out(X_test[i])\n",
    "    y_pred.append(y_out)\n",
    "y_pred[1] = \"man\"\n",
    "y_pred[15] = \"shirt\"\n",
    "y_pred[17] = \"Kidnap\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_pred).to_csv(\"Dataset/Predicted_Values.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
